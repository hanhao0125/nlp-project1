{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 新闻实体观点提取\n",
    "运行在服务器，standcorenlp 运行比较慢\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from gensim.models import KeyedVectors\n",
    "import random\n",
    "from pprint import pprint\n",
    "from pprint import pprint as pp\n",
    "base_path = '/root/files/'\n",
    "file_path = base_path + 'news_content.csv'\n",
    "nlp_path = '/root/stanford-corenlp'\n",
    "word2vec_model_path = base_path + 'sgns.merge.word.bz2'\n",
    "end = {'。','!','?'}\n",
    "say_represents = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 3 µs, total: 8 µs\n",
      "Wall time: 15 µs\n"
     ]
    }
   ],
   "source": [
    "wm = KeyedVectors.load_word2vec_format(word2vec_model_path,\n",
    "                                       binary=False, \n",
    "                                       unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'@Benjamin',\n",
      " 'LiveMint',\n",
      " 'Sangaku',\n",
      " 'Technobuffalo',\n",
      " 'swot',\n",
      " '一再强调',\n",
      " '一再表示',\n",
      " '一口咬定',\n",
      " '一方面',\n",
      " '三缄其口',\n",
      " '不久前',\n",
      " '不仅',\n",
      " '不仅如此',\n",
      " '不懂',\n",
      " '不是',\n",
      " '不过',\n",
      " '与此同时',\n",
      " '专访',\n",
      " '世称',\n",
      " '为什么',\n",
      " '为此',\n",
      " '举例',\n",
      " '之所以',\n",
      " '之说',\n",
      " '乌雷松',\n",
      " '也',\n",
      " '也许',\n",
      " '了解',\n",
      " '了解到',\n",
      " '争议',\n",
      " '争辩',\n",
      " '事后',\n",
      " '事实上',\n",
      " '于李浩',\n",
      " '亦称',\n",
      " '人士处',\n",
      " '人称',\n",
      " '什么',\n",
      " '介绍',\n",
      " '仔细分析',\n",
      " '他们',\n",
      " '传言',\n",
      " '传闻',\n",
      " '似乎',\n",
      " '但',\n",
      " '但是',\n",
      " '何参选',\n",
      " '你',\n",
      " '你问',\n",
      " '使得',\n",
      " '俗称',\n",
      " '值得一提的是',\n",
      " '全会也',\n",
      " '全会就',\n",
      " '关高通',\n",
      " '其实',\n",
      " '内情',\n",
      " '再问',\n",
      " '冒称',\n",
      " '写到',\n",
      " '写道',\n",
      " '出面',\n",
      " '函复',\n",
      " '分析',\n",
      " '则',\n",
      " '判断',\n",
      " '前不久',\n",
      " '力挺',\n",
      " '单看你',\n",
      " '南共在',\n",
      " '却说',\n",
      " '原因',\n",
      " '原是',\n",
      " '去找',\n",
      " '又称',\n",
      " '反复强调',\n",
      " '反问',\n",
      " '反驳',\n",
      " '反驳者',\n",
      " '发声明',\n",
      " '发表声明',\n",
      " '发表谈话',\n",
      " '另一方面',\n",
      " '只不过',\n",
      " '叫作',\n",
      " '叫做',\n",
      " '可是',\n",
      " '可能',\n",
      " '叹道',\n",
      " '合称',\n",
      " '同时',\n",
      " '向国港',\n",
      " '向宝沃',\n",
      " '向宝能',\n",
      " '向延足',\n",
      " '向旺成',\n",
      " '向深铁',\n",
      " '向科融',\n",
      " '向雷帝',\n",
      " '吗',\n",
      " '否定',\n",
      " '否认',\n",
      " '听其言观其行',\n",
      " '听说',\n",
      " '告诉',\n",
      " '告诉他',\n",
      " '呢',\n",
      " '和',\n",
      " '回复',\n",
      " '回应',\n",
      " '因为',\n",
      " '因此',\n",
      " '因而',\n",
      " '在发言中',\n",
      " '在我看来',\n",
      " '在此之前',\n",
      " '在讲话中',\n",
      " '坚称',\n",
      " '坦承',\n",
      " '坦言',\n",
      " '声称',\n",
      " '处理意见',\n",
      " '处理结果',\n",
      " '复信',\n",
      " '如是说',\n",
      " '媒体报道',\n",
      " '宝能早',\n",
      " '实际上',\n",
      " '宣布',\n",
      " '宣称',\n",
      " '对',\n",
      " '对于',\n",
      " '对於',\n",
      " '对此',\n",
      " '就',\n",
      " '就此',\n",
      " '尽管',\n",
      " '布瓦瑟利耶',\n",
      " '并且',\n",
      " '并未',\n",
      " '并称',\n",
      " '并说',\n",
      " '康德派',\n",
      " '引述',\n",
      " '强调',\n",
      " '强调指出',\n",
      " '归纳',\n",
      " '当事',\n",
      " '当然',\n",
      " '彭博社',\n",
      " '影射',\n",
      " '得出',\n",
      " '怀疑',\n",
      " '怎么',\n",
      " '怎么说',\n",
      " '恰如',\n",
      " '想问',\n",
      " '或许',\n",
      " '所以',\n",
      " '所言',\n",
      " '所讲',\n",
      " '所说',\n",
      " '打电话',\n",
      " '批评',\n",
      " '批驳',\n",
      " '承认',\n",
      " '报导',\n",
      " '抨击',\n",
      " '拒绝',\n",
      " '指',\n",
      " '指代',\n",
      " '指出',\n",
      " '指涉',\n",
      " '指称',\n",
      " '指责',\n",
      " '据',\n",
      " '据介绍',\n",
      " '据传',\n",
      " '据信',\n",
      " '据悉',\n",
      " '据称',\n",
      " '据说',\n",
      " '措辞',\n",
      " '描述',\n",
      " '提出',\n",
      " '提到',\n",
      " '提及',\n",
      " '提法',\n",
      " '提过',\n",
      " '援引',\n",
      " '摇摇头',\n",
      " '撇清',\n",
      " '数据分析',\n",
      " '无疑',\n",
      " '时说',\n",
      " '明白',\n",
      " '明确',\n",
      " '明确指出',\n",
      " '明确提出',\n",
      " '明确要求',\n",
      " '是',\n",
      " '是不是',\n",
      " '是因为',\n",
      " '显然',\n",
      " '暗指',\n",
      " '更何况',\n",
      " '有鉴于此',\n",
      " '本身',\n",
      " '本迪克松',\n",
      " '来信人',\n",
      " '来看',\n",
      " '来讲',\n",
      " '来说',\n",
      " '概括',\n",
      " '正像',\n",
      " '正如',\n",
      " '正象',\n",
      " '此事',\n",
      " '此前',\n",
      " '此外',\n",
      " '此案',\n",
      " '此次',\n",
      " '此番',\n",
      " '毁谤罪',\n",
      " '毕竟',\n",
      " '没听说过',\n",
      " '没错',\n",
      " '注重',\n",
      " '消息人士',\n",
      " '消息来源',\n",
      " '消息源',\n",
      " '澄清',\n",
      " '澄清事实',\n",
      " '然而',\n",
      " '特别强调',\n",
      " '现场采访',\n",
      " '理解',\n",
      " '用词',\n",
      " '由于',\n",
      " '疑问',\n",
      " '的',\n",
      " '的确',\n",
      " '的话',\n",
      " '直言',\n",
      " '相信',\n",
      " '相对于',\n",
      " '看来',\n",
      " '真华南虎',\n",
      " '真的',\n",
      " '着重',\n",
      " '着重强调',\n",
      " '着重指出',\n",
      " '矢口否认',\n",
      " '知情',\n",
      " '知情人',\n",
      " '知情者',\n",
      " '知道',\n",
      " '石磊就',\n",
      " '研究',\n",
      " '确',\n",
      " '确实',\n",
      " '称',\n",
      " '称为',\n",
      " '称之为',\n",
      " '称作',\n",
      " '称做',\n",
      " '称呼',\n",
      " '笑了笑',\n",
      " '笑着',\n",
      " '笑言',\n",
      " '笑道',\n",
      " '答复',\n",
      " '答道',\n",
      " '结论',\n",
      " '给出',\n",
      " '绝无此事',\n",
      " '缘故',\n",
      " '而',\n",
      " '而且',\n",
      " '而言',\n",
      " '耸了耸肩',\n",
      " '自封',\n",
      " '自称',\n",
      " '自称为',\n",
      " '自认是',\n",
      " '自诩',\n",
      " '至此',\n",
      " '范徐艳',\n",
      " '获悉',\n",
      " '获知',\n",
      " '虽然',\n",
      " '表态',\n",
      " '表明态度',\n",
      " '表示',\n",
      " '表达',\n",
      " '表述',\n",
      " '被称作',\n",
      " '要是',\n",
      " '要说',\n",
      " '见过',\n",
      " '观点',\n",
      " '视为',\n",
      " '觉得',\n",
      " '角度看',\n",
      " '解析',\n",
      " '解答',\n",
      " '解释',\n",
      " '言论',\n",
      " '认为',\n",
      " '认可',\n",
      " '认同',\n",
      " '认同感',\n",
      " '认知',\n",
      " '记者',\n",
      " '讲',\n",
      " '讲到',\n",
      " '讲解',\n",
      " '论据',\n",
      " '论点',\n",
      " '访谈',\n",
      " '证实',\n",
      " '诚如',\n",
      " '话说',\n",
      " '诟病',\n",
      " '该事',\n",
      " '说',\n",
      " '说一句',\n",
      " '说什么',\n",
      " '说得好',\n",
      " '说是',\n",
      " '说法',\n",
      " '说起',\n",
      " '说道',\n",
      " '请问',\n",
      " '谈到',\n",
      " '谈及',\n",
      " '谈最',\n",
      " '谈论',\n",
      " '谈起',\n",
      " '负责人',\n",
      " '质疑',\n",
      " '贾巧萍',\n",
      " '赞同',\n",
      " '跟',\n",
      " '路透社',\n",
      " '辟谣',\n",
      " '辩称',\n",
      " '辩解',\n",
      " '辩驳',\n",
      " '近期',\n",
      " '还是',\n",
      " '这事',\n",
      " '这番话',\n",
      " '透漏',\n",
      " '透漏出',\n",
      " '透露',\n",
      " '透露消息',\n",
      " '那样',\n",
      " '邱云又',\n",
      " '都',\n",
      " '都说',\n",
      " '采访',\n",
      " '释正义',\n",
      " '重申',\n",
      " '问',\n",
      " '问到',\n",
      " '问及',\n",
      " '问起',\n",
      " '问道',\n",
      " '问问',\n",
      " '阐述',\n",
      " '阐释',\n",
      " '阮文咏',\n",
      " '随即',\n",
      " '随后',\n",
      " '非议',\n",
      " '鞠传国',\n",
      " '预测',\n",
      " '马克东·巴伯',\n",
      " '驳斥',\n",
      " '高晓军',\n",
      " '高维数',\n",
      " '\\ue40c',\n",
      " '﹔',\n",
      " '？'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "def search(query,depth=3):\n",
    "    r = {}\n",
    "    all_r = [] \n",
    "    topn = 10\n",
    "    s = wm.most_similar(query,topn=topn)\n",
    "    r[0] = {query:s} \n",
    "    \n",
    "    for d in range(1, depth):\n",
    "        _v = r[d-1]\n",
    "        s = {}\n",
    "        for k,v in _v.items():\n",
    "            for i in v:\n",
    "                s[i[0]] = wm.most_similar(i[0],topn=topn)\n",
    "        r[d] = s\n",
    "#     pprint(r)\n",
    "    for _,v in r.items():\n",
    "        for _,k in v.items():\n",
    "            all_r += k \n",
    "#     print(all_r)\n",
    "    all_r = sorted(all_r,key=lambda x:x[1],reverse=True)\n",
    "    all_r = set([i[0] for i in all_r])\n",
    "    pp(all_r)\n",
    "    return all_r\n",
    "r = search('表示') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 读取新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89617</td>\n",
       "      <td>此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89616</td>\n",
       "      <td>骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89615</td>\n",
       "      <td>此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。 至于电...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89614</td>\n",
       "      <td>这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89613</td>\n",
       "      <td>（原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……） @深圳交警微博称：昨日清晨交警...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            content\n",
       "0  89617  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...\n",
       "1  89616  骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...\n",
       "2  89615  此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。 至于电...\n",
       "3  89614       这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄 \n",
       "4  89613  （原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……） @深圳交警微博称：昨日清晨交警..."
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv(file_path)\n",
    "d['content'] = d['content'].apply(lambda x:str(x)\n",
    "                                  .replace('\\n',' ')\n",
    "                                  .replace('\\\\n', ' ')\n",
    "                                  .replace('\\u3000',' '))\n",
    "sentences = d['content'].tolist()\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始处理，使用 ltp 提取实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyltp import NamedEntityRecognizer,Postagger,Segmentor\n",
    "segmentor = Segmentor()\n",
    "segmentor.load('/root/files/ltp_data_v3.4.0/cws.model')\n",
    "postagger = Postagger()\n",
    "postagger.load('/root/files/ltp_data_v3.4.0/pos.model')\n",
    "recongnizer = NamedEntityRecognizer()\n",
    "recongnizer.load('/root/files/ltp_data_v3.4.0/ner.model')\n",
    "\n",
    "\n",
    "# transpose to {'word':words,'entity':[[start,end,org_name]]}\n",
    "def ltp_ner(news):\n",
    "    mapper = {'Ni':'org_name','Nh':'person_name'}\n",
    "    ret = {'word':None,'entity':None}\n",
    "    words = segmentor.segment(news)\n",
    "    postags = postagger.postag(words)\n",
    "    nertags = s.recognize(words,postags)\n",
    "    entity = []\n",
    "    k = 0\n",
    "    while k < len(words):\n",
    "        if nertags[k] == 'O' or nertags[k].endswith('Ns'):\n",
    "            k += 1\n",
    "        elif nertags[k].startswith('S'):\n",
    "            entity.append([k,k+1,mapper[nertags[k][2:]]])\n",
    "            k += 1\n",
    "        elif nertags[k].startswith('B'):\n",
    "            start = k\n",
    "            while k < len(words) and not nertags[k].startswith('E'):k+=1\n",
    "            entity.append([start,k+1,mapper[nertags[k][2:]]])\n",
    "            k += 1\n",
    "        else:\n",
    "            k += 1\n",
    "    return {\n",
    "        'word':list(words),\n",
    "        'entity':entity\n",
    "    }\n",
    "\n",
    "def contains_say_keywords(c):\n",
    "    return any(True if i in c else False for i in say_represents)\n",
    "\n",
    "def uniteNER(news):\n",
    "    ner = ltp_ner(news)\n",
    "#     ner = nlp.ner(news)[0]\n",
    "    words = ner['word']\n",
    "    entity = ner['entity']\n",
    "    N = []\n",
    "    # record the entity start and end. k:v = start : end\n",
    "    entity_start = {}\n",
    "    for e in entity:\n",
    "        if e[2] in {'org_name','person_name'}:\n",
    "            entity_start[e[0]] = e[1]\n",
    "            N.append([''.join(words[e[0]:e[1]]),e[2]])\n",
    "    return N, entity_start, words\n",
    "\n",
    "def extract_points(news):\n",
    "    points = []\n",
    "    ners, es, words = uniteNER(news)\n",
    "    k = 0\n",
    "    while k < len(words):\n",
    "        if k in es:\n",
    "            # entity start, fetch the sentence\n",
    "            # first add the entity\n",
    "            _p = [''.join(words[k:es[k]])]\n",
    "            # second add the sentence\n",
    "            start = k\n",
    "            # find the finish signal\n",
    "            while k < len(words) and words[k] not in end:k+=1\n",
    "            _p.append(''.join(words[start:k]))\n",
    "            \n",
    "            points.append(_p)\n",
    "        k += 1\n",
    "    # filter the none points sentences. \n",
    "    # currently methods is naive: filter the sentence by keywords which can represent says\n",
    "    points = list(filter(lambda x: contains_say_keywords(x[1]),points))\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('中国经济网6月23日讯（记者刘瑾）日前，中国机械工业百强企业、汽车三十强企业名单出炉。在由中国机械工业联合会、中国汽车工业协会主办的“中国机械工业百强企业、汽车工业三十强企业信息发布会”上，中国机械工业联合会会长王瑞祥指出，入围企业总体呈现了持续增长态势，2016年总规模、平均规模均创新高，我国机械工业总体上呈现稳中向好的发展态势，主要经济指标出现恢复性增长。 '\n",
      " '同时，王瑞祥也表示，机械工业长期积累的结构性矛盾还没有根本性改变，新的发展业态、发展模式远未形成，保持平稳健康发展的基础还不牢固，产业升级、新旧动能转换、实现由大变强任重道远。 '\n",
      " '相关数据显示，2016年机械百强入围企业规模是15.4亿元，比上年略高。总规模达到16992亿元，平均规模169.92亿元，两项均创新高。相比前两年的前十强排名，名单基本没有什么变化，只是工程机械行业的徐工、三一和中联重科由于之前市场环境等原因，整体排位后移了一两位，但仍全部在十强之列。但考虑到工程机械行业最近以来的强烈增长态势，明年该行业整体恢复性可能较大。 '\n",
      " '中机联执行副会长陈斌表示，机械百强的年换位率2005年曾高达32%，此后逐年下降，2012年降至6%，不过近几年又在上升，2016年升至22%，说明市场动荡，不确定因素增加。 '\n",
      " '根据中机联公布的数据，2017年1至5月机械增加值增速好于去年但呈现逐月回落的态势，比如1至5月增速为10.7，比1至4月回落0.2点。此外利润总额也出现了同样的走势。专家分析，这是由于钢铁等原材料价格近期出现较大增幅，使得工业企业成本压力增大。 '\n",
      " '“产量同比增长表现抢眼的是工程机械类产品，已经有8个月保持高速增长。”同时，陈斌也表示了担忧，比如价格指数缓慢回升但远低于工业、原材料指数，固定资产投资增速仍较低迷，增速在多年回落之后继续在低位震荡徘徊。他表示，行业经济运行仍面临一定的下行压力，机械行业主要服务的钢铁、煤炭、电力及石油、化工等行业普遍处于产业结构深度调整期，其装备需求短期难以大幅增长。还有经过多年的高速发展，各类机械产品的社会保有量均达到了相当规模，对现役设备的更新改造维护已成为需求中的重要部分，这增加了增量回升的难度。 ')\n",
      "['中国机械工业联合会', '中国机械工业联合会、中国汽车工业协会主办的“中国机械工业百强企业、汽车工业三十强企业信息发布会”上，中国机械工业联合会会长王瑞祥指出，入围企业总体呈现了持续增长态势，2016年总规模、平均规模均创新高，我国机械工业总体上呈现稳中向好的发展态势，主要经济指标出现恢复性增长']\n",
      "['王瑞祥', '王瑞祥也表示，机械工业长期积累的结构性矛盾还没有根本性改变，新的发展业态、发展模式远未形成，保持平稳健康发展的基础还不牢固，产业升级、新旧动能转换、实现由大变强任重道远']\n",
      "['徐工', '徐工、三一和中联重科由于之前市场环境等原因，整体排位后移了一两位，但仍全部在十强之列']\n",
      "['陈斌', '陈斌表示，机械百强的年换位率2005年曾高达32%，此后逐年下降，2012年降至6%，不过近几年又在上升，2016年升至22%，说明市场动荡，不确定因素增加']\n",
      "['陈斌', '陈斌也表示了担忧，比如价格指数缓慢回升但远低于工业、原材料指数，固定资产投资增速仍较低迷，增速在多年回落之后继续在低位震荡徘徊']\n"
     ]
    }
   ],
   "source": [
    "news = sentences[101]\n",
    "pp(news)\n",
    "p = extract_points(news)\n",
    "for i in p:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 哈工大 ltp 工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['刘'] person_name\n"
     ]
    }
   ],
   "source": [
    "from pyltp import NamedEntityRecognizer,Postagger,Segmentor\n",
    "segmentor = Segmentor()\n",
    "segmentor.load('/root/files/ltp_data_v3.4.0/cws.model')\n",
    "postagger = Postagger()\n",
    "postagger.load('/root/files/ltp_data_v3.4.0/pos.model')\n",
    "recongnizer = NamedEntityRecognizer()\n",
    "recongnizer.load('/root/files/ltp_data_v3.4.0/ner.model')\n",
    "\n",
    "\n",
    "def ltp_prepare(news):\n",
    "    words = segmentor.segment(news)\n",
    "    postags = postagger.postag(words)\n",
    "    nertags = recongnizer.recognize(words,postags)\n",
    "    return nertags\n",
    "\n",
    "\n",
    "def ltp_ner(news):\n",
    "    mapper = {'Ni':'org_name','Nh':'person_name'}\n",
    "    ret = {'word':None,'entity':None}\n",
    "    words = segmentor.segment(news)\n",
    "    postags = postagger.postag(words)\n",
    "    nertags = recongnizer.recognize(words,postags)\n",
    "    entity = []\n",
    "    k = 0\n",
    "    while k < len(words):\n",
    "        if nertags[k] == 'O' or nertags[k].endswith('Ns'):\n",
    "            k += 1\n",
    "        elif nertags[k].startswith('S'):\n",
    "            entity.append([k,k+1,mapper[nertags[k][2:]]])\n",
    "            k += 1\n",
    "        elif nertags[k].startswith('B'):\n",
    "            start = k\n",
    "            while k < len(words) and not nertags[k].startswith('E'):k+=1\n",
    "            entity.append([start,k+1,mapper[nertags[k][2:]]])\n",
    "            k += 1\n",
    "        else:\n",
    "            k += 1\n",
    "    return {\n",
    "        'word':list(words),\n",
    "        'entity':entity\n",
    "    }\n",
    "\n",
    "\n",
    "def test_ltp_ner(ner):\n",
    "    words = ner['word']\n",
    "    entity = ner['entity']\n",
    "    for i in entity:\n",
    "        print(words[i[0]:i[1]],i[2])\n",
    "        \n",
    "test_ltp_ner(ltp_ner(news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stanfordcorenlp 需要自己组合。\n",
    "***\n",
    "\n",
    "##hit ltp 采用BIESO 标注体系，可以直接看出 ner 类别，然后手工合并，效果不错,参考\n",
    "https://pyltp.readthedocs.io/zh_CN/latest/api.html\n",
    "https://ltp.readthedocs.io/zh_CN/latest/appendix.html#id4\n",
    "![](image/ner.png)\n",
    "***\n",
    "## bosonnlp 有次数限制，每天 ner 500 次，效果还可以\n",
    "bosonlp最好用。\n",
    "***\n",
    "刘奶奶的肿瘤已经扩大并转移至肛门，癌细胞也已扩散，令人惋惜。\n",
    "bosonnlp 可以识别出刘奶奶，但 ltp 只能识别出刘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyltp.VectorOfString object at 0x7f7ecaf53390>\n",
      "S-Nh\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, unicode_literals\n",
    "from bosonnlp import BosonNLP\n",
    "news = '刘奶奶的肿瘤已经扩大并转移至肛门，癌细胞也已扩散，令人惋惜。'\n",
    "pp(ltp_prepare(news))\n",
    "for i in ltp_prepare(news):\n",
    "    print(i)\n",
    "# nlp = BosonNLP('cKWUytiR.34676.f5F2YbS_EyX2')\n",
    "# print(nlp.ner(news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存在的问题\n",
    "\n",
    "网易财经6月28日讯中国银行行长李礼辉在6月28日举行的2013陆家嘴论坛上表示，建议适时取消贷款利率浮动的下限。适当精简人民币基准利率的档次，提高作为基准利率的使用范围和影响力。他认为，现在人民币基准利率的档次比较多，不管是存款的基准利率还是贷款的基准利率应该适当的精简，提高作为基准利率的使用范围和影响力。在实体经济可以承受的前提下，增强人民币汇率的弹性，扩大外汇市场参与主体，增加交易的品种，人民币与更多的外币直接交易，形成更多的直接的双边汇率。以下是发言实录：李礼辉第二个建议，深化利率市场化的改革，形成内外均衡的人民币价格，充分发挥市场在资源配置中的基础性的作用。下一个阶段，我们将可以适时取消贷款利率浮动的下限，适当精简人民币基准利率的档次，现在人民币基准利率的档次比较多，我们认为不管是存款的基准利率还是贷款的基准利率应该适当的精简，提高作为基准利率的使用范围和影响力。在实体经济可以承受的前提下，增强人民币汇率的弹性，扩大外汇市场参与主体，增加交易的品种，人民币与更多的外币直接交易，形成更多的直接的双边汇率。李礼辉中国银行已经在上海设立了总部，专业化经营人民币交易业务。中国银行业是香港、澳门、台湾、马来西亚等国家和地区的人民币的清算行，中国银行所做的人民币的跨境业务居市场的前列，我们将致力于提升上海作为国际金融中心的定位和作用，致力于促进香港新加坡等地跨境人民币业务的发展，我们希望能够为人民币的国际化做出我们应有的贡献。谢谢！李礼辉第三，离岸在岸的人民币市场协同发展，继续拓展香港人民币离岸市场的广度和深度，发挥香港离岸中心的作用。积极推动其他国际中心发展离岸人民币市场，逐步形成全球的人民币市场体系，同时加强境内和境外市场的衔接，积极探索在境内发展境外人民币业务，特别加快上海国际金融中心的建设，加强上海在跨境人民币产品创新，交易、定价和清算等方面的作用。本文来源：网易财经责任编辑：王晓易0011\n",
    "## resluts\n",
    "中国银行:中国银行行长李礼辉在6月28日举行的2013陆家嘴论坛上表示，建议适时取消贷款利率浮动的下限\n",
    "看到实体应该是李礼辉，但是由于先匹配到了中国银行，所以本剧的主题被列为中国银行。\n",
    "*** \n",
    "可以对生成的结果进行再次处理，查看 keyword 与实体的距离，并令距离最近的实体为最终实体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
